{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install pandas\n",
    "%pip install datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Settings to be configured per individual. \n",
    "\n",
    "TODO: configure these settings outside of the notebook so they don't mess with source control. (environment variables?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('.github_token', 'r') as f:\n",
    "        authtoken = f.read()\n",
    "except FileNotFoundError:\n",
    "    # get an auth token using the steps here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token\n",
    "    authtoken = input('Please enter your GitHub token: ')\n",
    "    with open('.github_token', 'w') as f:\n",
    "        f.write(authtoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "resultsDownloadLocation = 'c:\\\\temp\\\\testResults'\n",
    "if (not os.path.exists(resultsDownloadLocation)):\n",
    "    os.makedirs(resultsDownloadLocation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data\n",
    "\n",
    "The github action \"Aggregate Test Results\" runs daily and collects all the results for the previous day into a single json file.\n",
    "\n",
    "These steps will:\n",
    "\n",
    "- Find the last 50 runs (you can increase this if you want to look back further\n",
    "- Download the artifacts from those runs into memory\n",
    "- Write the .json file from within the artifact to disk (only if there isn't already an up to date file on disk)\n",
    "- Load all results into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def getRuns():\n",
    "    runsResponse = requests.get(\n",
    "        \"https://api.github.com/repos/microsoft/vscode-jupyter/actions/workflows/aggregate-test-results.yml/runs?per_page=50\",\n",
    "        headers={\n",
    "            \"Accept\": \"application/vnd.github+json\",\n",
    "            \"Authorization\": f\"Bearer {authtoken}\",\n",
    "            },   \n",
    "    )\n",
    "    \n",
    "    if runsResponse.status_code != 200:\n",
    "        print(f\"Error {runsResponse.status_code}\")\n",
    "        raise Exception(\"Error getting runs\")\n",
    "\n",
    "    print(f\"Found {len(runsResponse.json()['workflow_runs'])} runs\")\n",
    "\n",
    "    return runsResponse.json()[\"workflow_runs\"]\n",
    "\n",
    "runs = getRuns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "alreadyDownloaded = {}\n",
    "for file in os.listdir(resultsDownloadLocation):\n",
    "    path = os.path.join(resultsDownloadLocation, file)\n",
    "    lastModified = datetime.fromtimestamp(os.path.getmtime(path))\n",
    "    alreadyDownloaded[file] = lastModified\n",
    "\n",
    "print(f\"Already downloaded {len(alreadyDownloaded)} result files, they will be skipped unless there is a newer version\")\n",
    "\n",
    "def shouldDownload(name, timestamp):\n",
    "    fileDate = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    if name in alreadyDownloaded:\n",
    "        if alreadyDownloaded[name] >= fileDate:\n",
    "            return False\n",
    "            \n",
    "    alreadyDownloaded[name] = fileDate\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "\n",
    "def getArtifactData(id):\n",
    "    testResultsResponse = requests.get(\n",
    "        f\"https://api.github.com/repos/microsoft/vscode-jupyter/actions/artifacts/{id}/zip\",\n",
    "        headers={\n",
    "            \"Accept\": \"application/vnd.github+json\",\n",
    "            \"Authorization\": f\"Bearer {authtoken}\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if testResultsResponse.status_code != 200:\n",
    "        print(f\"Error {testResultsResponse.status_code} getting artifact {id}\")\n",
    "\n",
    "    return testResultsResponse.content\n",
    "\n",
    "def saveResultsFile(zipData, timeStamp):\n",
    "    with zipfile.ZipFile(io.BytesIO(zipData)) as artifact:\n",
    "        for name in artifact.namelist():\n",
    "            print(f'checking {name} at {timeStamp}')\n",
    "            if shouldDownload(name, timeStamp):\n",
    "                content = artifact.read(name)\n",
    "                print(f\"    saving {name}\")\n",
    "                with open(f'{resultsDownloadLocation}\\\\{name}', 'wb') as f:\n",
    "                    f.write(content) \n",
    "\n",
    "print(f\"Getting artifacts from {len(runs)} runs\")\n",
    "for run in runs:\n",
    "    artifactUrl = run[\"artifacts_url\"]\n",
    "    print(f\"Getting artifacts from {artifactUrl} from {run['created_at']}\")\n",
    "    artifactsResponse = requests.get(\n",
    "        artifactUrl, headers={\n",
    "            \"Accept\": \"application/vnd.github+json\",\n",
    "            \"Authorization\": f\"Bearer {authtoken}\",\n",
    "            }\n",
    "    )\n",
    "\n",
    "    if artifactsResponse.status_code != 200:\n",
    "        print(f\"Error {artifactsResponse.status_code} getting artifact {id}\")\n",
    "    else:\n",
    "        artifacts = artifactsResponse.json()[\"artifacts\"]\n",
    "        for artifact in artifacts:\n",
    "            rawData = getArtifactData(artifact[\"id\"])\n",
    "            testRunResults = saveResultsFile(rawData, run[\"created_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "testResults = []\n",
    "for file in os.listdir(resultsDownloadLocation):\n",
    "    path = f'{resultsDownloadLocation}\\\\{file}'\n",
    "    if datetime.fromtimestamp(os.path.getmtime(path)) < datetime.now() - timedelta(days=50):\n",
    "        # limit the amount of results we load\n",
    "        continue\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        try:\n",
    "            df = pd.read_json(f)\n",
    "            testResults.append(df)\n",
    "        except Exception as e:\n",
    "            print(f'Error reading {file}: {e}')\n",
    "\n",
    "df = pd.concat(testResults)\n",
    "# strip off the time to help grouping, but keep as datetime type\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "\n",
    "print(f\"{len(df)} test results collected between {df['date'].min()} and {df['date'].max()}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "recentFailures = df[df['date'] > date.today() - timedelta(days=7)]\n",
    "recentFailures = recentFailures[recentFailures['status'] == 'failed'].dropna()\n",
    "# recentFailures = recentFailures[recentFailures['scenario'] != 'TestLogs-raw-nonConda-3.10---windows-latest']\n",
    "recentFailures = recentFailures.groupby(['testName', 'suite']).agg(failureCount=('testName', 'count'))\n",
    "\n",
    "recentFailures.sort_values(by=['failureCount', 'suite'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure of a specific test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testName= 'Cells from python files and the input box are executed in correct order'\n",
    "\n",
    "testData = df.where(df['testName'] == testName).dropna()\n",
    "passes = testData.where(testData['status'] == 'passed').dropna()\n",
    "fails = testData.where(testData['status'] == 'failed').dropna()\n",
    "successRate = len(passes) / (len(passes) + len(fails))\n",
    "print(f\"'{testName}' failed {len(fails)} times between {testData['date'].min()} and {testData['date'].max()}\")\n",
    "print(f\"Success rate: {successRate}\")\n",
    "\n",
    "testData['fail'] = testData['status'] == 'failed'\n",
    "testData['pass'] = testData['status'] == 'passed'\n",
    "\n",
    "passfailcounts = testData.groupby(['date']).sum()\n",
    "\n",
    "passfailcounts.sort_values(by=['date'], ascending=False).head(15)\n",
    "\n",
    "# line chart not working\n",
    "# import matplotlib.pyplot as plt\n",
    "# ax=testData.plot(kind='line', x='date', y='pass', color='Green')\n",
    "\n",
    "# ax2=testData.plot(kind='line', x='date', y='fail', secondary_y=True,color='Red', ax=ax)\n",
    "\n",
    "# ax.set_ylabel('Passes')\n",
    "# ax2.set_ylabel('Failures')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = testData.where(testData['status'] == 'failed').dropna()\n",
    "failures = failures[['date', 'status', 'scenario', 'runUrl']].sort_values(by=['date'], ascending=False).head(10)\n",
    "\n",
    "failureMessage = ''\n",
    "for index, row in failures.iterrows():\n",
    "    print(f\"{row['date']} - {row['scenario']}\\n{row['runUrl']}\")\n",
    "    failureMessage += f\"{row['date']} - {row['scenario']}\\n{row['runUrl']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from urllib import request\n",
    "\n",
    "\n",
    "# post to create new github issue\n",
    "def createIssue(title, body):\n",
    "    print(\"Creating issue for \" + title)\n",
    "    url = 'https://api.github.com/repos/microsoft/vscode-jupyter/issues'\n",
    "    data = {\n",
    "        'title': title,\n",
    "        'body': body,\n",
    "        'labels': ['flaky test']\n",
    "    }\n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"Authorization\": f\"Bearer {authtoken}\",\n",
    "    }\n",
    "    data = json.dumps(data).encode('utf-8')\n",
    "    req = request.Request(url, data=data, headers=headers, method='POST')\n",
    "    response = request.urlopen(req)\n",
    "    print(response.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "chk = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Create issue on github?',\n",
    "    disabled=False,\n",
    "    indent=False\n",
    ")\n",
    "display(chk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (chk.value):\n",
    "    createIssue(f\"Test failure: {testName}\", failureMessage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05cadb55cbb23d0d156eeac1bfe39405b391b4fa73e06b1a6140e7007eb56649"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
